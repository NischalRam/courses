= Loading Data Quiz
:order: 2
:type: quiz

== Neo4j Data Importer: A Visual Tool

The Neo4j Data Importer is a visual tool that simplifies the process of importing data into your Neo4j database. It provides an intuitive interface that allows you to map your data to the graph model. This tool supports various data formats, including CSV, JSON, and XML.

== LOAD CSV: Importing CSV Data

LOAD CSV is a built-in command in Cypher, Neo4j's query language. It is used to import CSV data into a Neo4j database. The command reads CSV files, processes the data, and creates nodes and relationships in the graph database.

Here is a basic example of how to use LOAD CSV:

[source,cypher]
----
LOAD CSV WITH HEADERS FROM 'file:///path/to/your/data.csv' AS row
CREATE (:Person {name: row.name, age: toInteger(row.age)});
----

In this example, the `LOAD CSV` command reads a CSV file with headers. Each row in the CSV file is represented as a map in the `row` variable. The `CREATE` statement then creates a new `Person` node for each row, with properties set from the CSV data.

== neo4j-admin import: A Fast Offline Importer

The `neo4j-admin import` tool is a powerful command-line utility that allows for fast, offline data imports. This tool bypasses the transactional layer, which makes it significantly faster than other import methods when dealing with large datasets.

Here is a basic example of how to use `neo4j-admin import`:

[source,shell]
----
neo4j-admin import --database=graph.db --nodes=Person=/path/to/your/persons.csv --relationships=FRIENDS=/path/to/your/friends.csv
----

In this example, the `neo4j-admin import` command imports data from two CSV files: one for `Person` nodes and one for `FRIENDS` relationships.

== Best Practices for Data Preparation and Performance Optimization

When preparing your data for import, there are several best practices to follow for optimal performance:

* **Data Cleaning:** Ensure your data is clean and consistent. This includes removing duplicates, handling missing values, and ensuring data types are consistent.

* **Indexing:** Create indexes on properties that will be used in queries. This can significantly improve query performance.

* **Batching:** When importing large datasets, break the data into smaller batches. This can help manage memory usage and improve performance.

* **Using Periodic Commit:** The `USING PERIODIC COMMIT` statement can be used with the `LOAD CSV` command to commit transactions in batches. This can help manage memory usage when importing large datasets.

Here is an example of how to use `USING PERIODIC COMMIT` with `LOAD CSV`:

[source,cypher]
----
USING PERIODIC COMMIT 500
LOAD CSV WITH HEADERS FROM 'file:///path/to/your/data.csv' AS row
CREATE (:Person {name: row.name, age: toInteger(row.age)});
----

In this example, the `USING PERIODIC COMMIT` statement commits the transaction every 500 rows. This can be adjusted based on the size of your dataset and the available memory.

Remember, data import is a critical step in creating your knowledge graph. By understanding and utilizing these tools and best practices, you can ensure a smooth and efficient data import process.

== Check Your Understanding

include::questions/1-neo4j-data-importer.adoc[leveloffset=+1]

include::questions/2-load-csv-command.adoc[leveloffset=+1]

include::questions/3-neo4j-admin-import-tool.adoc[leveloffset=+1]

[.summary]
== Lesson Summary

TODO: Generate lesson summary
